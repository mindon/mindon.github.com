<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Light-Air-Water-M-Sci | Mindon.IDEA]]></title>
  <link href="http://mindon.github.com/blog/categories/light-air-water-m-sci/atom.xml" rel="self"/>
  <link href="http://mindon.github.com/"/>
  <updated>2012-08-04T17:49:26+08:00</updated>
  <id>http://mindon.github.com/</id>
  <author>
    <name><![CDATA[Mindon Feng]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Web Lab]]></title>
    <link href="http://mindon.github.com/blog/2012/08/04/web-lab/"/>
    <updated>2012-08-04T17:28:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/08/04/web-lab</id>
    <content type="html"><![CDATA[<p>"Web Lab. A series of interactive Chrome Experiments made by Google. See the magic of the web brought to life. Open to the world online. Live from the Science Museum, London. "</p>

<p>这是个很好玩的实验室。Google建的一个位于伦敦的科学馆。科学馆里配置了一些设备：如乐器和沙绘机器人（Sketchbots）。您可以通过他们的网站来编曲演奏乐器，跟世界上其他地方的人合奏。也可以通过摄像头拍照，让科学馆的机器人绘制您的头像——所有这一切，您都可以通过现场摄像头看到真实科学馆的设备看到设备的现场实时操作。很不可思议吧？您在体验一家位于伦敦的科学馆。</p>

<p>体验一下？<a href="http://www.chromeweblab.com/">Web Lab</a> :-) You need a <a href="https://www.google.com/intl/en/chrome/browser/">Chrome Browser</a>(<a href="https://www.google.com/intl/zh-CN/chrome/browser/">中文版</a>), I think.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[B-Z Reaction]]></title>
    <link href="http://mindon.github.com/blog/2012/08/04/b-z-reaction/"/>
    <updated>2012-08-04T10:40:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/08/04/b-z-reaction</id>
    <content type="html"><![CDATA[<p>　　1921年，伯克利加州大学的布雷(Bray，William)在用碘作催化剂使过氧化氢分解为水和氧气时，第一次发现了振荡式的化学反应。但依据经典热力学第二定律，认为任何化学反应只能走向退化的平衡态，因而当时的化学家否定了这个发现。</p>

<p>　　1952年，英国数学家图灵通过数学计算的方法，在理论上预见了化学振荡这类现象的可能性。1958年，俄国化学家别洛索夫(Belousov) 和扎鲍廷斯基(Zhabotinskii)首次报道了以金属铈作催化剂，柠檬酸在酸性条件下被溴酸钾氧化时可呈现化学振荡现象：溶液在无色和淡黄色两种状态间进行着规则的周期振荡。该反应即被称为Belousov- Zhabotinskii反应，简称B-Z反应。</p>

<p><img src="/images/blog/250px-The_Belousov-Zhabotinsky_Reaction.gif" alt="" /></p>

<p>Computer simulation of the Belousov–Zhabotinsky reaction occurring in a Petri dish.</p>

<!--more-->


<p>　　在1959年，B.P.Belousov首先观察到并随后为A.M.Zhabotinsky深入研究，丙二酸在溶液有硫酸铈的酸性溶液中被溴酸钾氧化的反应，随后人们发现了一大批可呈现化学振荡反应现象的含溴酸盐的反应系统。人们称之为B-Z反应。</p>

<p>　　1969年，现代动力学奠基人普里戈金提出耗散结构理论，人们才清楚的认识到振荡反应产生的原因：当体系远离平衡态时，即在非平衡非线性区，无序的均匀态并不总是稳定的。在特定的动力学条件下，无序的均匀定态可以失去稳定性，产生时空有序的状态，这种状态称之为耗散结构。例如浓度随时间有序的变化(化学振荡)，浓度随时间和空间有序的变化(化学波)等。耗散结构理论的建立为振荡反应提供了理论基础，从此，振荡反应赢得了重视，它的研究得到了迅速发展。</p>

<p>　　化学振荡是一类机理非常复杂的化学过程，Field、Koros、Noyes三位科学家经过四年的努力，于1972年提出俄勒冈（FKN）模型，用来解释并描述B-Z振荡反应的很多性质。该模型包括20个基元反应步骤，其中三个有关的变量通过三个非线性微分方程组成的方程组联系起来，该模型如此复杂以至20世纪的数学尚不能一般地解出这类问题，只能引入各种近似方法。</p>

<p>The discovery of the phenomenon is credited to Boris Belousov. He noted, some time in the 1950s (various sources date ranges from 1951 to 1958), that in a mix of potassium bromate, cerium(IV) sulfate, propanedioic acid and citric acid in dilute sulfuric acid, the ratio of concentration of the cerium(IV) and cerium(III) ions oscillated, causing the colour of the solution to oscillate between a yellow solution and a colorless solution. This is due to the cerium(IV) ions being reduced by propanedioic acid to cerium(III) ions, which are then oxidized back to cerium(IV) ions by bromate(V) ions.</p>

<p>Belousov made two attempts to publish his finding, but was rejected on the grounds that he could not explain his results to the satisfaction of the editors of the journals to which he submitted his results. His work was finally published in a less respectable, non-reviewed journal.</p>

<p>Later, in 1961, a graduate student named Anatol Zhabotinsky rediscovered this reaction sequence; however, the results of these men's work were still not widely disseminated, and were not known in the West until a conference in Prague in 1968.</p>

<p>http://en.wikipedia.org/wiki/Belousov%E2%80%93Zhabotinsky_reaction</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The eye limits the brain's learning potential]]></title>
    <link href="http://mindon.github.com/blog/2012/04/26/the-eye-limits-the-brains-learning-potential/"/>
    <updated>2012-04-26T08:12:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/04/26/the-eye-limits-the-brains-learning-potential</id>
    <content type="html"><![CDATA[<p>The concept of a critical period for visual development early in life during which sensory experience is essential to normal neural development is now well established. However recent evidence suggests that a limited degree of plasticity remains after this period and well into adulthood. Here, we ask the question, "what limits the degree of plasticity in adulthood?" Although this limit has been assumed to be due to neural factors, we show that the optical quality of the retinal image ultimately limits the brain potential for change. We correct the high-order aberrations (HOAs) normally present in the eye's optics using adaptive optics, and reveal a greater degree of neuronal plasticity than previously appreciated.</p>

<p>[<a href="http://www.nature.com/srep/2012/120413/srep00364/full/srep00364.html">read the full version article</a>]</p>

<p>Nature集团新刊《Scientific Reports》于4月16日在线发表了中国科学技术大学脑功能与脑疾病中科院重点实验室及生命科学学院周逸峰研究小组和中国科学院成都光电技术研究所自适应光学重点实验室张雨东研究小组的合作研究成果。</p>

<p>他们通过实验证明，即便是发育成熟之后正常成年视觉神经系统仍具有相当程度的可塑性，但这些可塑性的发挥受限于人眼的光学系统质量。在使用人眼自适应光学矫正仪提高人眼光学系统质量后进行知觉学习训练可以大幅度提高正常成人的视觉功能。</p>

<!--more-->


<p>视觉神经科学中的一个基本理论是“视皮层的发育具有关键期”，在关键期关闭之前视皮层较容易被改变，而关键期关闭之后则较难被改变。目前，很多知觉学习上的证据表明，即使是成年的视皮层也存在一定的可塑性。然而，对正常成人而言，这种在知觉学习过程中体现出的可塑性虽然存在，其程度却非常小。这极大的限制了知觉学习在提高成人视功能中应用。</p>

<p>另一方面，视光学领域的研究者发现：人眼并非一个完美的光学系统，除了大家所熟知的近视、远视和散光等在内的低阶像差外，还存在大量的难以用普通光学手段测量和矫正的高阶像差。近些年来，使用原先应用在天文学上的自适应光学矫正技术，视光学领域的研究者们通过矫正人眼高阶像差部分提高了成人视功能。但对正常成人而言，这种视功能上的提高很微弱，远达不到理论期望值；且无法脱离自适应光学矫正仪器而存在，因此也无法有效应用于成人视力的提高中。</p>

<p>尽管视知觉学习与人眼自适应光学这两个领域的研究者们对如何更好的提高视功能都报以极大的研究热情，但限于研究手段的单一，目前两方面的研究都在一定程度上达到了瓶颈。双方都迫切需要跨学科的先进技术与之结合来扩展思路。而到目前为止，结合自适应光学技术研究视知觉学习的学习效果、相关机制及应用的研究鲜有报道。在此背景下，周逸峰研究小组和张雨东研究小组将视知觉学习与人眼自适应光学技术相结合，取得了创新研究成果。</p>

<p>他们比较了在矫正人眼高阶像差情况下（此时有较理想的人眼光学系统）对比度检测任务的知觉学习和不矫正人眼高阶像差情况下（普通的人眼光学系统）同样任务的知觉学习中，被试者对比敏感度和视力提高程度的差异。结果发现，在知觉学习训练后高阶像差矫正组在对比敏感度和视力上都有了显著的提高，而且这种提高至少可以维持5个月以上；而非高阶像差矫正组对比敏感度只有少量提高，视力水平无显著提高。</p>

<p>他们的结果表明，发育关键期之后的正常成年视觉神经系统仍具有相当程度的可塑性，但这些可塑性的发挥受限于训练时人眼的光学系统成像质量。只有当高阶像差被矫正时，视觉系统的可塑性才能得到发挥。该发现可以用于探索新的治疗方法来提高视力低下患者的视功能。同时，还为结合人眼自适应光学矫正技术和视知觉学习来达到“超视力”提供了可能。</p>

<p>这项研究工作是在国家重点基础研究发展计划973项目、国家自然科学基金重点项目、成都光电所前沿研究项目等基金的共同资助下完成。加拿大McGill大学视觉研究所所长Robert Hess教授一起合作完成了部分实验设计、数据处理及论文写作工作。本工作的技术部分于2011年9月20日获得两项美国发明专利授权。</p>

<p><a href="http://biox.ustc.edu.cn/xydt/201204/t20120417_133360.html">来源 - 中科大生命学院</a></p>

<p><a href="http://211.157.104.87:8080/sipo/zljs/hyjs-yx-new.jsp?recid=CN200910262470.4&amp;leixin=fmzl&amp;title=%C8%CB%D1%DB%D7%D4%CA%CA%D3%A6%B9%E2%D1%A7%CA%D3%D6%AA%BE%F5%D1%A7%CF%B0%D1%B5%C1%B7%B7%BD%B7%A8%BA%CD%D1%A7%CF%B0%D1%B5%C1%B7%D2%C7">国家专利链接</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lasers Can Be Used to Steer Lightning In Mid-Strike]]></title>
    <link href="http://mindon.github.com/blog/2012/03/15/lasers-can-be-used-to-steer-lightning-in-mid-strike/"/>
    <updated>2012-03-15T22:23:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/15/lasers-can-be-used-to-steer-lightning-in-mid-strike</id>
    <content type="html"><![CDATA[<p>Laser light can not only trigger lightning but redirect it, causing it to strike in the same place over and over, according to new research. This means lasers could serve as lightning rods. Because that would be awesome.</p>

<p>Laser lightning rods have been a research subject for several decades, because they could trigger lightning and guide it to a specific place. Firing a laser would create an ionized channel in the atmosphere, which could conduct the lightning to the ground. Laser lightning rods could be an alternative to lightning rockets, according to Aurlien Houard of the Laboratoire d'Optique Appliquée in Palaiseau, France, a co-author of this study. Lightning rockets can apparently trigger a lightning strike by bringing a conductive material, like some type of salts, toward the static layer of a thunderhead. But a laser would be easier to control than a rocket.</p>

<p>A team of French researchers set out to test how well lasers can harness and control lightning. They sent a laser beam past a spherical electrode toward an oppositely charged flat electrode. The laser stripped away the outer electrons from the atoms in its way, ionizing the pathway between the electrodes and creating a plasma filament — like lab lightning — that channeled an electrical discharge from the flat electrode to the spherical one.</p>

<p>Then the team added a longer, pointed electrode to their set of electrode shapes and watched what happened. Left to its own devices, lightning follows the path of least resistance, striking the first thing it comes across — in a thunderstorm, that’s the tallest thing, and in this experiment, it’s the nearest thing. With no laser lightning rod, the discharge predictably hit the tall pointed electrode first. But when the researchers used the laser filament to guide it, the electrical discharge followed the ionized path and hit the spherical electrode instead.</p>

<p>The team found they could pull this off even after the discharge was already on its way, meaning they could divert the path of lightning. The research appears in the American Institute of Physics journal <a href="http://aipadvances.aip.org/resource/1/aaidbi/v2/i1/p012151_s1?bypassSSO=1">AIP Advances</a>.</p>

<p>Original from POPSCI: <a href="http://www.popsci.com/technology/article/2012-03/lightning-can-strike-twice-if-you-have-some-lasers">Lasers Can Be Used to Steer Lightning In Mid-Strike</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Inside the Lytro: Light Field Camera]]></title>
    <link href="http://mindon.github.com/blog/2012/03/05/inside-the-lytro-light-field-camera/"/>
    <updated>2012-03-05T21:32:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/05/inside-the-lytro-light-field-camera</id>
    <content type="html"><![CDATA[<p>The New York Times: <a href="http://www.nytimes.com/interactive/2012/03/01/business/inside-the-lytro.html">Inside the Lytro</a></p>

<p>The Lytro camera is the first consumer “light field camera.” It uses a new technology to create photos that can have their focus changed after they have been taken. Because of this, there is no need to auto-focus, resulting in virtually no shutter delay. Here’s how it works.</p>

<h2>Camera Overview</h2>

<p>A Lytro camera is made up of two sections. An anodized aluminum shell contains the lens assembly, while the electronics are housed within a silicone rubber grip.</p>

<p><img src="/images/blog/lytro-cross-section.jpg" alt="" /></p>

<!--more-->


<h2>Capturing Light</h2>

<p>Lytro’s light field sensor captures not only the color, intensity and position of the light, but also its direction, which is lost in traditional cameras.</p>

<h2>Changing Focus</h2>

<p>Because all the directional information of the entering light is captured, software can change the focal plane. Clicking any point on the image brings that area into focus, whether raindrops on the surface of a window or buildings beyond.</p>

<h2>Light Field Sensor</h2>

<p>Consists of a standard digital camera CMOS sensor coupled with a micro-lens array. The array contains thousands of miniature lenses.</p>

<h2>Micro-Lens Array</h2>

<p>Tiny lenses divide the CMOS sensor’s pixels into multiple areas, each showing the image at a slightly different angle. Software uses this data to triangulate the image in 3-D space.</p>

<h2>Controlling the Camera</h2>

<p>Lytro uses a 1.46-inch touch screen. Swiping back and forth allows you to view previous or later photos, while swiping up brings up a menu bar. The shutter button and a slider for the zoom are molded into the top of the unit, while the power button and a USB connector are on the bottom.</p>

<p><a href="https://www.lytro.com/science_inside">Lytro: Science Inside</a>, <a href="http://www.lytro.com/">Lytro</a></p>

<p><a href="http://graphics.stanford.edu/papers/fourierphoto/">http://graphics.stanford.edu/papers/fourierphoto/</a></p>

<h2>Lytro Light Field Camera</h2>

<p><strong>GOOD STUFF</strong></p>

<ul>
<li><p>Light Field technology is amazing</p></li>
<li><p>Gorgeous, conversation-starting design</p></li>
<li><p>Fast and reliable performance</p></li>
</ul>


<p><strong>BAD STUFF</strong></p>

<ul>
<li><p>Aside from the focusing effect, image quality is mediocre</p></li>
<li><p>Only works really well in a few situations</p></li>
<li><p>Desktop software is a bear</p></li>
</ul>


<p><a href="http://www.theverge.com/2012/2/29/2821763/lytro-review">Lytro Review</a></p>

<p>Lytro是一家位于硅谷的创业公司，源于公司CEO Ren Ng在斯坦福的一项研究，其目标很简单：凭借其光场（light field）相机「硬件和软件」，Lytro可以从很多方面改变照相技术，因为有了它你无需对焦。</p>

<p>与此同时，这家公司的投资方包括Andreessen Horowitz和Greylock等知名投资机构，其技术团队包括Silicon Graphics联合创始人以及Palm webOS的首席架构师。那么Lytro的魅力到底在哪里呢？</p>

<p>答案是「光场（light field）照相」或者说「全光（plenoptic）照相」。Lytro背后的核心思维源于斯坦福的一篇论文「PDF文档」，原理非常简单。普通相机的工作原理和肉眼差不多，前面的镜头可以收集来自前方的光线，然后通过传感器上的光圈「单反相机上的硅胶套或眼睛里的视网膜」。为了聚焦眼睛或普通照相机，你通过不同方式调整镜头，以捕捉来自不同方向的光线，将其收集到传感器中。这会带来很多副作用，其中之一就是只能有一个焦点。这让问题变得复杂，当然如果手法得当的话可以拍出漂亮的照片。</p>

<p>但Lytro的技术之一就是在相机传感器前面布有大量微镜头。你可以把它们想象成苍蝇眼睛上的数千个微型镜头。其中的物理学和数学知识有点复杂，但最后的结果是这样的：相机传感器记录下的不是单一的图像「由镜头、光圈等设置决定」，Lytro相机可以用复杂的方式记录下来自前方场景各个部位的光线，而不仅仅是普通相机那样只能记下聚焦范围中的光线。然后Lytro软件会对图像进行解码。</p>

<p><embed src="http://player.youku.com/player.php/sid/XMjc5NDc5NDY4/v.swf" allowFullScreen="true" quality="high" width="480" height="400" align="middle" allowScriptAccess="always" type="application/x-shockwave-flash"></embed></p>

<p>这就是神奇之处。因为这个系统可以捕捉有关场景光线方向的信息，因此它可以“聚焦”照片中的任何深度，哪怕在拍照后数年。一瞬间你就可以获得理想的照片，相机可以去掉笨重、耗电和昂贵的聚焦系统，你可以更快地完成拍照，即便非专业摄影师也不必担心对焦问题。镜头还可以捕捉弱光环境下的光线。这会产生很大的影响，可能会对整个相机业带来巨大变革。</p>

<p>... 36氪<a href="http://www.36kr.com/p/30873.html">Lytro光场相机原理和应用浅析</a></p>
]]></content>
  </entry>
  
</feed>
