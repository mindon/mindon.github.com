<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Web-Tech | Mindon.IDEA]]></title>
  <link href="http://mindon.github.com/blog/categories/web-tech/atom.xml" rel="self"/>
  <link href="http://mindon.github.com/"/>
  <updated>2012-07-15T00:19:14+08:00</updated>
  <id>http://mindon.github.com/</id>
  <author>
    <name><![CDATA[Mindon Feng]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Serve in Multi-Languages]]></title>
    <link href="http://mindon.github.com/blog/2012/06/12/serve-in-multi-languages/"/>
    <updated>2012-06-12T23:00:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/06/12/serve-in-multi-languages</id>
    <content type="html"><![CDATA[<p>When we want our product -- a webpage for example -- servered in multi-languages, what would we do?</p>

<p>Simple once working method is copy-n-translate:  Making a full copy of original language resource, translate and replace the texts. It's a hard and dirty work.</p>

<p>Unless a few simple pages, no one will do it in this way nowdays.</p>

<p>We like to use text-id and text resources in our projects: desktop applications, J2EE projects, php websites ...</p>

<p>But all of these are working in the same mode: Template + Text-Resources + Tool = Result</p>

<!--more-->


<p><img src="/images/blog/multi-langs.png" alt="" /></p>

<p>(pro: proposition, con: contradition)</p>

<h2>Template</h2>

<ul>
<li><strong>Raw language text as text-resource-id</strong></li>
</ul>


<p>pro: Readable, directly simple, no extra work but replacement. One language file is template itself.</p>

<p>con: Dirty work, if same text appears, you have to manual replace them all.</p>

<h1>q/s#: Could we make maual-process auto?</h1>

<ul>
<li><strong>Named ID as text-resource-id</strong></li>
</ul>


<p>pro: Avoid repeat work on same phrases or sentences.</p>

<p>con: Named IDs' management, unintuitive templates using named IDs.</p>

<h1>q/s#: Could we auto-generate the named IDs and avoid unintuitive templates?</h1>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Build Node-Expat Under Windows]]></title>
    <link href="http://mindon.github.com/blog/2012/06/11/build-node-expat-under-windows/"/>
    <updated>2012-06-11T09:22:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/06/11/build-node-expat-under-windows</id>
    <content type="html"><![CDATA[<h2>Preparea Developemtn Environment</h2>

<p>To build node-expat module under windows, you need the nodejs addon development env ready.</p>

<ul>
<li><p>Get and install VC++ 2010 Express from microsoft: 【<a href="http://www.microsoft.com/visualstudio/en-us/products/2010-editions/visual-cpp-express">Download VC++ 2010 Express</a>】</p></li>
<li><p>Download and unzip the NodeJS source code from Joyent's github project: 【<a href="https://github.com/joyent/node">Download NodeJS source code</a>】</p></li>
<li><p>Get and install Python 2.7</p></li>
<li><p>Run <code>vcbuild.bat Release</code> under such as <strong>joyen-node/</strong> (where you unzip the source of nodejs) to build NodeJS.</p></li>
</ul>


<h2>Tools for building a NodeJS Module</h2>

<ul>
<li><p>Env variable set <strong>NODE_ROOT</strong>=<em>where-your-joyent-node-located</em></p></li>
<li><p>Check the <strong>tools/</strong> folder in the joyent-node/: file <strong>gyp_addon</strong>, and <strong>addon.gypi</strong> are needed.</p></li>
</ul>


<!--more-->


<p>if they are not exists, try get it from the latest tag from github of joyent-node ( Left of Files tab, find branch --> Tags ).</p>

<p>( You could use tools/<strong>gyp_node</strong> directly )</p>

<h2>Node-Expat Dependencis:</h2>

<ul>
<li><p>Install Expat under windows
<a href="http://sourceforge.net/projects/expat/files/latest/download">http://sourceforge.net/projects/expat/files/latest/download</a></p></li>
<li><p>Env variable set <strong>EXPAT_ROOT</strong>=<em>where-your-Expat-installed</em></p></li>
<li><p>Append the <strong>Bin/</strong> of Expat to <strong>PATH</strong> env.</p></li>
</ul>


<h2>Building Node-Expat:</h2>

<ul>
<li><p>Prepare <strong>build.gyp</strong> ( need to change D:/Expat to your expat root )</p>

<pre><code>{
  'variables' : {
    'target_arch': 'ia32'
  },
  'targets': [
    {
      'target_name': 'node-expat',
      'sources': [ 'node-expat.cc' ],
      'include_dirs': [
    'd:/Expat/Source/lib/'
      ],
      'libraries': [
    '-ld:/Expat/Bin/libexpat.lib'
      ]
    }
  ],
}
</code></pre></li>
<li><p>Run following commands</p></li>
</ul>


<p>to setup build version and msbuild tool env.</p>

<pre><code>@set Configuration=Release
"D:\Microsoft Visual Studio 10.0\VC\vcvarsall.bat"
</code></pre>

<p>then</p>

<pre><code>python d:\joyent-node\tools\gyp_addon build.gyp

msbuild build\build.sln
</code></pre>

<p>Now you should build the Node-Expat. But you may meet other problems:</p>

<h2>Testing</h2>

<p>if run node and require("./build/Release/node-expat") fail, it may be caused by following reasons:</p>

<p><strong>a)</strong>  check the node-expat.cc, and make sure there's a <strong>NODE_MODULE_EXPORT</strong> or <strong>NODE_EXTERN</strong> before the <em>void init</em></p>

<p>something like this: <code>extern "C" NODE_EXTERN void init(Handle&lt;Object&gt; target)</code></p>

<p><strong>b)</strong> if "unable to load shared library" error, try copy <strong>libexpat.dll</strong> to the folder of <strong>node.exe</strong> located.</p>

<ul>
<li> <strong>node test.js</strong></li>
</ul>


<p>if when you run <code>node test.js</code> of expat, it may fail. Then you need following code to fix it.</p>

<pre><code>char *toCString(v8::Local&lt;v8::Value&gt; value, const char *fallback = "") {
    if (value-&gt;IsString()) {
    v8::String::Utf8Value string(value);
    char *str = (char *) malloc(string.length() + 1);
    strcpy(str, *string);
    return str;
    }
    char *str = (char *) malloc(strlen(fallback) + 1);
    strcpy(str, fallback);
    return str;
}
</code></pre>

<p>add these code below <code>using namespace node;</code>.</p>

<p>then change the line around 155 before or 165 after code above added</p>

<pre><code>return XML_ParseBuffer(parser, len, isFinal) != XML_STATUS_ERROR;
</code></pre>

<p> into</p>

<pre><code>return XML_Parse(parser, toCString(&amp;str, ""), len, isFinal) != XML_STATUS_ERROR;
</code></pre>

<p>This patch could help to remove the error "<strong>not well-formed (invalid token)</strong>".</p>

<p>Now, your node-epxat under windows is ready for node-soap, you would need this for something like WSDL!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Zettabyte FileSystem: ZFS]]></title>
    <link href="http://mindon.github.com/blog/2012/06/08/zettabyte-filesystem-zfs/"/>
    <updated>2012-06-08T10:50:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/06/08/zettabyte-filesystem-zfs</id>
    <content type="html"><![CDATA[<p>知道ZFS: Zettabyte FileSystem 说到头是从NodeJS开始的。</p>

<p>因为NodeJS开发下需要关注CPU占用和内存泄漏问题，了解到了 DTrace, mdb —— 这些 Solaris 系统下的跟踪调试工具。后来接触到了 SmartOS 系统 —— Joyent已经把这个基于Illumos的操作系统开源了。（2010 年 8 月 3 日，illumos 正式可用。「Illumos」这个词来自 Illuminare，也即拉丁语的 Illuminate，「照明、照亮」的意思。illumos 项目的最终目标有两个：一是使用开源代码取代所有仍在 OpenSolaris 使用的专有代码，二是围绕之前的OpenSolaris 代码库建立一个独立的社区。）</p>

<p>SmartOS由Illumos内核（包括ZFS，DTrace，Zones，OS级虚拟化以及下一代KVM）、BSD包管理器和GNU工具链组成。【<a href="https://github.com/joyent/smartos-live">源码</a>】,【<a href="https://download.joyent.com/pub/iso/">Live ISO</a>】</p>

<h2>Why SmartOS?</h2>

<ul>
<li>Scale as fast and big as you need</li>
</ul>


<p>SmartOS is a hypervisor lean enough to run entirely in memory, powerful enough to run as much as you want to throw at it. Provisioning is blindingly fast, thanks to zones and ZFS file system creation.</p>

<ul>
<li>Trust it to keep your data safe</li>
</ul>


<p>The ZFS file system guarantees data integrity, with particular emphasis on preventing silent data corruption.</p>

<ul>
<li>Keep your system secure with "double hulled" virtualization</li>
</ul>


<p>OS virtualization with highly secure sparse zones (most system software is read-only), and KVM for legacy apps, provide the most secure virtualization on the market.</p>

<ul>
<li>Rely on It</li>
</ul>


<p>Based on the <a href="http://illumos.org/">illumos</a> kernel, a descendant of Solaris - the most trusted enterprise operating system in computing history. Additionally, SmartOS runs from a live image: there's no such thing as a failed upgrade when you can simply roll back to an earlier image.</p>

<ul>
<li>Use and extend freely: it’s open source</li>
</ul>


<p>SmartOS is and will remain <a href="http://smartos.org/cddl/">open source</a>. Joyent contributes <a href="https://github.com/joyent/smartos-live">our core kernel</a> work to the <a href="http://illumos.org/">illumos</a> project.</p>

<ul>
<li>Manage resources better</li>
</ul>


<p>The Service Management Facility (SMF) helps you recover more quickly from system failures and manage through service slowdowns. Fair share scheduling, CPU caps, and disk I/O throttling ensure good neighbor behavior in massively multi-tenant environments.</p>

<ul>
<li>See what’s going on throughout the software stack, in real time</li>
</ul>


<p>When something doesn’t behave as it should, you need to be able to find out quickly what is wrong and why. <a href="http://wiki.smartos.org/display/DOC/DTrace+Resources">Dynamic tracing</a> lets you see everything that's happening throughout the software stack - safely, in real time, in production.</p>

<h2>ZFS特性介绍(转载)</h2>

<p><img src="/images/blog/zfstour.png" alt="" /></p>

<p>from <a href="http://hub.opensolaris.org/bin/view/Community+Group+zfs/source">http://hub.opensolaris.org/bin/view/Community+Group+zfs/source</a></p>

<p>ZFS是第一个128位的文件系统，同时ZFS又被Sun Microsystems称作史上最后一个文件系统。因为这个文件系统含有多项创新技术，不仅成功地解决现有文件系统的问题和陋习，而且前瞻性地考量了未来对存储空间的需求，单个文件系统可以达到256 quadrillion（264） Zettabytes（221）。ZFS不仅符合POSIX文件系统的标准，而且提供了许多高级功能比如：Quota(配额)，Reservation(预留), Compression(压缩)， Snapshot(快照)，Clone（克隆）等。如果你还在坚持使用现有32位或者64位的文件系统，如果你还在“痛并不快乐着”地用着各式各样的Volume Manager，那就很值得看看这里列出的使用ZFS的十条理由。</p>

<!--more-->


<ol>
<li><p><strong>再也不需要fsck, scandisk</strong></p>

<p>不管你是在用Linux，UNIX还是Windows，相信大家都有过类似的体会：当系统意外断电或者非法关机，系统重起后发现文件系统有inconsistent的问题，这时 候就需要fsck或者scandisk 来修复，这段时间是非常耗时而且最后不一定能够修复成功。更糟糕的是，如果这是一台服务器需要做fsck的时候，只能offline（下线），而且现有应用往往都是大硬盘，相应fsck修 复时间也很长，这对许多使用该服务器的用户来说几乎不能忍受的。</p>

<p>而使用ZFS后大家可以彻底抛弃fsck这种工具，因为ZFS是一个基于COW（Copy on Write）机制的文件系统。COW是不会对硬盘上现有的文件进行重写，保证所有硬盘上的文件都是有效的。所以不会有这种inconsistent的概念，自然就不需要这种工具了。</p></li>
<li><p><strong>管理简单</strong></p>

<p>ZFS作为一个全新的文件系统，全面抛弃传统File System + Volume Manager + Storage的架构，所有的存储设备是通过ZFS Pool进行管理，只要把各种存储设备加 入同一个ZFS Pool，大家就可以轻松的在这个ZFS Pool管理配置文件系统。大家再也不用牢记各种专业概念，各种命令newfs, metinit及各种Volume Manager的用法。在ZFS中我们只需要两个命令，zpool(针 对ZFS Pool管理)和zfs(针对ZFS文件系统的管理)，就可以轻松管理128位的文件系统。举个例子，我们经常会遇到系统数据增长过 快，现有存储容量不够，需要添加硬盘，如果依照传统的Volume Manager管理方式，那我 们需要预先要考虑很多现有因素，还要预先根据应用计算出需要配置的各种参数。在ZFS情况下，我们的系统管理员可以彻底解放，再也不需要这种人为的复杂 考虑和计算，我们可以把这些交给ZFS，因为ZFS Pool会自动调节，动态适应需求。我们只需一个简单的命令为 这个ZFS Pool加入新的硬盘就可以了：</p>

<pre><code>zpool add zfs_pool mirror c4t0d0 c5t0d0
</code></pre>

<p>基于这个动态调节的ZFS Pool之上的所有的文件系统就可以立即使用到这个新的硬盘，并且会自动的选择最优化的参数。</p></li>
<li><p><strong>没有任何容量限制</strong></p>

<p>ZFS（Zettabyte File System）文件系统就如其名字所预示，可以提供真正的海量存储，在现实中几乎不可能遇到容量问题。在现有的64位kernel（内 核）下，它可以容纳达到16 Exabytes(264)大小的单个文件，可以使用264个存储设备，可以创建264个文件系统。</p></li>
<li><p><strong>完全保证 数据 的正确和完整</strong></p>

<p>由于ZFS所有的数据操作都是基 于Transaction（事务），一组相应的操作会被ZFS解 析为一个事务操作，事务的操作就代表着一组操作要么一起失败，要么一起成功。而且如前所说，ZFS对 所有的操作是基于COW（Copy on Write）， 从而保证设备上的数 据始终都是有效的，再也不会因为系统崩溃或者意外掉电导致数据文件的inconsistent。</p>

<p>还有一种潜在威胁 数据的可能是来自于硬件设备的问题，比如磁 盘，RAID卡的硬件问题或者驱动bug。现有文件系统通常遇到这个问题，往往只是简单的把错误数据直接交给上层应用，通常我们把这个问题称作Silent Data Corruption。而在ZFS中，对所有数据不管是用户数据还是文件系统自身的metadata数 据都进行256位的Checksum（校 验），当ZFS在提交数据时会进行校验，彻底杜绝这种Silent Data Corruption情况。</p></li>
<li><p><strong>提供优异 性能和扩展性</strong></p>

<p>和传统File System + Volume Manager + Storage架构不同，ZFS则是直接基于存储设备提供所有的功能，因此有自己独有的创新特性，性能自然非比寻常。</p>

<p><strong>Dynamic Striping vs. Static Striping</strong></p>

<p>由于ZFS是基于COW和一个全局动态的ZFS Pool，任何一次写 操作，都是对一块新数据块（Block）的一次写操作。ZFS从ZFS Pool中动态挑选出一个最优的设备，并且以一个transaction（事 务）线性写入，充分有效地利用了现有设备的带宽，我们把这个特性称为Dynamic Striping。而相对应的Static Striping则是传统文件系统所使用的方式，Static Striping需要管理员预先对这组Stripe进行正确地计算人为 设置，而且如果加入新的设备则需要再次人为的计算和设置，更为严重的是如果人为计算错误，则会直接影响系统的性能。而在使用Dynamic Striping这种特性之后，我们根本不需要人为介入，ZFS会自动调整，智能的为你 提供最佳的设备，最快的操作方式。</p>

<p><strong>支持多种 大小的数据块（Multiple Block Size）</strong></p>

<p>ZFS支持多种大小的数据块定义，从512字节到1M字节。和传统文件系统往往都是固定大小数据块不同，ZFS则是可以动态的根据不同 大小的文件进行计算，动态的选择最佳的数据块。</p>

<p>因为不同大小数据 块，直接影响到实际使用硬盘容量和读取速度。如果使用较小的数据块，存储文件所导致的碎片则较少，读写小文件更快一些，但是会导致需要创建更多的metadata，读写大文件则会更费时。如果使用较大的数据块，使用的metadata较少，更利于读写大文件，但是会导致更多的碎片。ZFS根据实际调查现有文件使 用的情况，分析出一个选择数据块大小的算法，动态的根据实际文件大小确定最佳的数据块。所以ZFS是 非常智能的，在不需要系统管理员介入，就可以得到一个自我调优的结果。当然ZFS也支持用户对单个文件或者整个文件系统 所使用的数据块大小的自定义设置。</p>

<p><strong>智能预读取（Intelligent Prefetch）</strong></p>

<p>多数的操作系统都 有这种将数据预先读取的功能，而ZFS则是建立在文件系统上直接提供的一种更加智能的数据预读取功能。它不仅可以智能地识别出多种读取模式， 进 行提前读取数据，而且可以对每个读取数据流进行这种预读取智能识别，这个对许多流媒体提供者来说是件非常好的事情。</p>

<p>在扩展性上，和现有文件系统多是基于一个受限的静态模型不同，ZFS是采用ZFS Pool这个动态概念，它的metadata也是动态，并且读写操作都是可并行的，并且具有优先级概念，所以即使在大数据量，多设备的情况下仍可以保证性能的线性增长。</p></li>
<li><p><strong>自我修复功能</strong></p>

<p><strong>ZFS Mirror 和 RAID-Z</strong></p>

<p>传统的硬盘Mirror及RAID 4，RAID 5阵列方式都会遇到前面提到过的问题：Silent Data Corruption。如果发生了某块硬盘物理问题导致数据错误，现有的Mirror，包括RAID 4，RAID 5阵列会默默地把这个错误数据提交给上层应用。如果这个错误发生在Metadata中，则会直接导致系统的Panic。 而且还有一种更为严重的情况是：在RAID 4和RAID 5阵列中，如果系统正在计算Parity数值，并再次写入新数据和新Parity值的时候发生断电，那么整个阵列的所有存储的数据都毫无意义了。</p>

<p>在ZFS中则提出了相对应的ZFS Mirror和RAID-Z方式，它在负责读取数据的时候会自动和256位校验码进行校验，会主动发现这种Silent Data Corruption，然后通过相应的Mirror硬 盘或者通过RAID-Z阵列中其他硬盘得到正确的数据返回给上层应用，并且同时自动修复原硬盘的Data Corruption 。</p>

<p><strong>Fault Manager</strong></p>

<p>在Solaris 10中，包含 一个ZFS诊断引擎和Solaris的 Fault Manager（这也是Solaris 10的 另一个新特性）交互，可以实时地诊断分析并且报告ZFS Pool和存储设备的错误，用户可以通过Fault Manager及时得到一个非常友善的消息。这个诊断引擎虽然不会采取主动的行为去修复或者解决 问题，但是会在消息中提示系统管理员可采取的动作。类似下面一个ZFS报错消息，其中REC-ACTION就是建议采取的动作：</p>

<pre><code>SUNW-MSG-ID: ZFS-8000-D3, TYPE: Fault, VER: 1, SEVERITY: Major
EVENT-TIME: Fri Mar 10 11:09:06 MST 2006
PLATFORM: SUNW,Ultra-60, CSN: -, HOSTNAME: neo
SOURCE: zfs-diagnosis, REV: 1.0
EVENT-ID: b55ee13b-cd74-4dff-8aff-ad575c372ef8
DESC: A ZFS device failed. Refer to &lt;http://sun.com/msg/ZFS-8000-D3&gt; for more information.
AUTO-RESPONSE: No automated response will occur.
IMPACT: Fault tolerance of the pool maybe compromised.
REC-ACTION: Run ’zpool status -x’ and replace the bad device.
</code></pre></li>
<li><p><strong>安全</strong></p>

<p>在安全上，ZFS支持类似NT风格NFSv4版的ACL（读取控制列表）。而且前面所提到的256位验证码，用户可选择多种验证方式，包括SHA-256验证算法，从而在物理存储单元级别上保证数据的安全性。</p></li>
<li><p><strong>超强功能</strong></p>

<p>ZFS作为“最后一个文件系统”，涵盖了基本的文件系统和Volume管理的功能，同时 一并提供许多企业级别的超强功能：Quota(配额)，Reservation(预留), Compression(压 缩)， Snapshot(快照)，Clone（克隆）。并且速度非常快。有了这个文件系统，大家再也不需要任何Volume Manager了。</p></li>
<li><p><strong>兼容性</strong></p></li>
</ol>


<p>ZFS是一个完全兼容POSIX规范的文件系统，所以处于上层的应用程序是完全不受影响。ZFS也提供一个Emulated Volume模块，可以把任何一个ZFS文件系统作为普通的块设备使用。同时ZFS也可以使用基于Volume Manager构建的Volume作为存储设备单 元。这样在不需要修改应用程序，不修改已有文件系统下，给了大家最大的自由度去获得ZFS提供的各 种特性。</p>

<p>10。 <strong>开源</strong></p>

<p>ZFS是Sun Microsystems公 司作为OpenSolaris的一个开源项目运作并且完全免费使用，点击这里(<a href="http://www.opensolaris.org/os/community/zfs/source/">http://www.opensolaris.org/os/community/zfs/source/</a>) 可以直接浏览到ZFS的代码。 这就代表着我们不仅同时可以享受商业公司的高质量，也可以获得开源模式的优点。</p>

<p>虽然目前只有Solaris支持该文件系统，但是这种开源的模式必定会促进更多基于ZFS的应用。现在已经有国外开发者正在将ZFS移植到Linux和Mac OS上来。如果想要体验一下ZFS，由于目前它和Solaris 10绑定在一起，所以需要下载最新版的Solaris 10 6/06 (<a href="http://www.sun.com/software/solaris/get.jsp">http://www.sun.com/software/solaris/get.jsp</a>)。</p>

<p><strong>参考:</strong></p>

<p>Solaris ZFS Administration Guide: <a href="http://docs.sun.com/app/docs/doc/819-5461?l=zh&amp;q=ZFS">http://docs.sun.com/app/docs/doc/819-5461?l=zh&amp;q=ZFS</a></p>

<p>Solaris 10 Zone FAQ: <a href="http://www.sun.com/software/solaris/faqs/zfs.xml">http://www.sun.com/software/solaris/faqs/zfs.xml</a>
Automatic Performance Tuning in the Zettabyte File System:  <a href="http://tesla.hpl.hp.com/self-manage03/Finals/henson-self-tune.pdf">http://tesla.hpl.hp.com/self-manage03/Finals/henson-self-tune.pdf</a></p>

<p>Other: <a href="http://www.ibm.com/developerworks/cn/linux/l-zfs/">在 Linux 上运行 ZFS</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Profiling Node.JS Application]]></title>
    <link href="http://mindon.github.com/blog/2012/04/26/profiling-nodejs-application/"/>
    <updated>2012-04-26T07:22:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/04/26/profiling-nodejs-application</id>
    <content type="html"><![CDATA[<h2>NodeJS</h2>

<p>Call something like "ulimit -n 8192" in your NodeJS App start shell script, before start your nodejs service.</p>

<p>Running with --prof to generate the v8.log</p>

<pre><code>node --prof --prof_lazy app.js
</code></pre>

<p>with tools in /node/deps/v8/, you can get report like following:</p>

<p>(run <code>tools/linux-tick-processor path-of-v8.log</code>)</p>

<pre><code>[Shared libraries]:
   ticks  total  nonlib   name
      3    0.0%    0.0%  .../libc-2.13.so

[JavaScript]:
   ticks  total  nonlib   name
      1    0.0%    0.0%  Stub: InstanceofStub

[C++]:
   ticks  total  nonlib   name
     1    0.0%    0.0%  __write
     ...

[GC]:
   ticks  total  nonlib   name
     15    0.0%

[Bottom up (heavy) profile]:
  Note: percentage shows a share of a particular caller in the total
  amount of its parent calls.
  Callers occupying less than 2.0% are not shown.

   ticks parent  name
   ...
</code></pre>

<p>trace log</p>

<pre><code>strace -o trace.log -cf node app.js:
</code></pre>

<p>or simple get the time</p>

<pre><code>time node app.js
</code></pre>

<h2>Other Modules &amp; Tools</h2>

<ul>
<li><a href="http://dtrace.org"><strong>dtrace</strong></a></li>
</ul>


<p>read the nodejs blog <a href="http://blog.nodejs.org/2012/04/25/profiling-node-js/">http://blog.nodejs.org/2012/04/25/profiling-node-js/</a></p>

<pre><code>dtrace -o stacks.out -n 'profile-97/execname == "node" &amp;&amp; arg1/{
  @[jstack(100, 8000)] = count(); } tick-60s { exit(0); }'
</code></pre>

<ul>
<li><strong>v8-profiler</strong></li>
</ul>


<p>@Github <a href="https://github.com/dannycoates/v8-profiler">https://github.com/dannycoates/v8-profiler</a></p>

<!--more-->


<pre><code>var profiler = require('v8-profiler');

profiler.startProfiling('startup');
slowStartupFoo();
profiler.stopProfiling('startup');

profiler.takeSnapshot('beforeLeak');
leakyFoo();
profiler.takeSnapshot('afterLeak');
</code></pre>

<ul>
<li><strong>node-inspector</strong></li>
</ul>


<p>@Github <a href="https://github.com/dannycoates/node-inspector">https://github.com/dannycoates/node-inspector</a></p>

<pre><code>node --debug app.js
</code></pre>

<ul>
<li><strong>node-profiler</strong></li>
</ul>


<p>@Github <a href="https://github.com/bnoordhuis/node-profiler">https://github.com/bnoordhuis/node-profiler</a></p>

<pre><code>var profiler = require('profiler');
//
// &lt;here be code you don't want to profile&gt;
//
profiler.resume();
//
// &lt;performance critical code here&gt;
//
profiler.pause();
</code></pre>

<ul>
<li><strong>Nodetime</strong>
<a href="http://nodetime.com/">http://nodetime.com/</a></li>
</ul>


<p>Nodetime reveals response time and other internals of HTTP requests and underlying HTTP / database calls in your Node.js application. Coupled with related process and OS state information it enables tracing performance problems down to the root cause. Nodetime supports multiple native and external APIs and libraries.</p>

<pre><code>var nodetime = require('nodetime');
nodetime.on('session', function(id) {
  // do something with session id here
});
nodetime.profile();
</code></pre>

<ul>
<li><strong>Callgrind</strong></li>
</ul>


<p>Callgrind is a profiling tool that records the call history among functions in a program's run as a call-graph. By default, the collected data consists of the number of instructions executed, their relationship to source lines, the caller/callee relationship between functions, and the numbers of such calls. Optionally, cache simulation and/or branch prediction (similar to Cachegrind) can produce further information about the runtime behavior of an application.</p>

<p><a href="http://valgrind.org/docs/manual/cl-manual.html">http://valgrind.org/docs/manual/cl-manual.html</a></p>

<pre><code>valgrind --tool=callgrind node app.js
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Find out Unique Elements in a Javascript Array]]></title>
    <link href="http://mindon.github.com/blog/2012/04/17/find-out-unique-javascript-array-elements/"/>
    <updated>2012-04-17T22:53:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/04/17/find-out-unique-javascript-array-elements</id>
    <content type="html"><![CDATA[<p>To remove duplicate elements in a array, there are a few algorithms to implement.</p>

<h2>Algorithm 1</h2>

<pre><code>function unique1(d) {
  var o = {}, i, l = d.length, r = [];
  for(i=0; i&lt;l;i+=1) o[d[i]] = d[i];
  for(i in o) r.push(o[i]);
  return r;
};
</code></pre>

<p>This method has 2 loops, that's a big time-cost problem.</p>

<h2>Algorithm 2</h2>

<p>reduce one loop from the algorithm 1, improve a litter bit</p>

<pre><code>function unique2(d) {
  var r = [], i = {}, j = 0;
  for(var k=0, kmax=d.length; k&lt;kmax; k++) {
    if(!i[d[k]]) {
      i[d[k]] = 1;
      r[j++]=d[k];
    }
  }
  return r;
}
</code></pre>

<h2>Algorithm 3</h2>

<p>In ECMA-262 standard, there's a indexOf method for Array object, we use it to improve a lot.</p>

<pre><code>function unique3(d) {
  var r = [], j = 0;
  for(var k=0, kmax=d.length; k&lt;kmax; k++) {
    if(r.indexOf(d[k]) &lt; 0) {
      r[j++]=d[k];
    }
  }
  return r;
}
</code></pre>

<p>and it could be better...</p>

<!--more-->


<h2>Algorithm 4</h2>

<p>jQuery.unique source ( Sizzle.uniqueSort ), it's the fastest one.</p>

<pre><code>function unique4( d ) {
  d.sort();
  for (var i = 1; i &lt; d.length; i++ ) {
    if ( d[i] === d[ i - 1 ] ) {
      d.splice( i--, 1 );
    }
  }

  return d;
};
</code></pre>

<h2>Compare these 4 algorithms:</h2>

<p>Speed(Performance): 4 > 3 > 2 > 1</p>

<p>Testing code:</p>

<pre><code>var d = [1, 3, 2, '2'];

function test(fn, count) {
  var t = new Date().getTime();
  for(var k =0 ; k &lt; count; k++) {
    fn(d);
  }

  return new Date().getTime() - t;
}

var t1 = test(unique1, 100000);
var t2 = test(unique2, 100000);
var t3 = test(unique3, 100000);
var t4 = test(unique4, 100000);
</code></pre>

<p>Time consume result sample:</p>

<p>IE 9(in Editplus):</p>

<pre><code>[t1,t2,t3,t4] = [93, 55, 25, 25]
</code></pre>

<p>IE 9(Browser):</p>

<pre><code>[t1,t2,t3,t4] = [508, 449, 432, 271]
</code></pre>

<p>Chrome 18:</p>

<pre><code>[t1,t2,t3,t4] = [141, 59, 43, 43]
</code></pre>

<p>Firefox 11:</p>

<pre><code>[t1,t2,t3,t4] = [129, 118, 25, 37]
</code></pre>

<p>(use == instead of === in unique4 will make it a little bit faster.)</p>

<h2>Problems</h2>

<p>handling a array with different data types:</p>

<pre><code>var d = [1, 3, 2, '2'];
</code></pre>

<p>results:</p>

<pre><code>unique1(d) : [1, '2', 3]

unique2(d) : [1, 3, 2]

unique3(d) : [1, 3, 2, '2']

unique4(d) : [1, 2, '2', 3]
</code></pre>

<p>if we change the === in unique4 into ==, then the new result will be</p>

<pre><code>unique4(d) : [1, 2, 3]
</code></pre>

<p>Another issue is the order problem:</p>

<p>unique1 and unique4 will re-order elements.</p>

<p>unique2 and unique3 will keep the original order.</p>

<p>Algorithm 3: unique3 depends on indexOf of ECMA-262 standard implement, and it cannot handle different data types.</p>

<h2>Conclusion</h2>

<ul>
<li>Same data-type elements</li>
</ul>


<p>orgianl order: <strong>unique3</strong></p>

<p>sorted: <strong>unique4</strong></p>

<ul>
<li>Different data-type elements ( thinking '2' is the same as 2 )</li>
</ul>


<p>orgianl order: <strong>unique2</strong></p>

<p>sorted: <strong>unique4</strong> (!NOTICE: change === into == )</p>

<ul>
<li>Different data-type elements ( thinking '2' is different from 2 )</li>
</ul>


<p>orgianl order: <strong>unique3</strong></p>

<p>sorted: <strong>unique4</strong> (!NOTICE: keep === )</p>

<p>以上为去除数组中的重复元素的各种算法，性能及问题。</p>

<p>--- Mindon(麦盾) Apri 18, 2012 Shenzhen(深圳)</p>

<p>（整理这样一篇东西还挺耗时的，子时了zZzZZz... ）</p>
]]></content>
  </entry>
  
</feed>
