<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Web-Tech | Mindon.IDEA]]></title>
  <link href="http://mindon.github.com/blog/categories/web-tech/atom.xml" rel="self"/>
  <link href="http://mindon.github.com/"/>
  <updated>2012-03-23T08:42:45+08:00</updated>
  <id>http://mindon.github.com/</id>
  <author>
    <name><![CDATA[Mindon Feng]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Magic Code Switching Comment Syntax]]></title>
    <link href="http://mindon.github.com/blog/2012/03/22/magic-code-switching-comment-syntax/"/>
    <updated>2012-03-22T23:58:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/22/magic-code-switching-comment-syntax</id>
    <content type="html"><![CDATA[<p>This a kind of c-style code comments to switch two blocks of code for debug or testing.</p>

<pre><code>/*/
  //... Section A (commented)
/*/
  //... Section B (working)
//*/
</code></pre>

<p>By adding one single / at the beginning, it turns into:</p>

<pre><code>//*/
  //... Section A (working)
/*/
  //... Section B (commented)
//*/
</code></pre>

<p>Another simple section comment:</p>

<pre><code>//*/
  //... working
//*/
</code></pre>

<p>remove a single / at the beginning, it turns into:</p>

<pre><code>/*/
  //... commented
//*/
</code></pre>

<ul>
<li><p>Curiosity</p></li>
<li><p>Passion</p></li>
<li><p>Focus</p></li>
<li><p>Fun</p></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Javascript Micro-Templating]]></title>
    <link href="http://mindon.github.com/blog/2012/03/21/javascript-micro-templating/"/>
    <updated>2012-03-21T10:52:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/21/javascript-micro-templating</id>
    <content type="html"><![CDATA[<p>This is a modification version of <strong>John Resig</strong>'s <a href="http://ejohn.org/blog/javascript-micro-templating/">Javascript Micro-Templating</a></p>

<p>The modifications are mostly about filter for field values:</p>

<p>Example: change some value in different formats.</p>

<p>I like this javascript mico-templating code from <a href="http://ejohn.org/"><strong>John Resig</strong></a>, it's really simple, easy-to-use.</p>

<pre><code>(function(){
  var cache = {};

  // Added by Mindon
  this.tmplCall = {
    nohtml: function(v) {
      return typeof v == 'string'
        ? v.replace(/&amp;/g,'&amp;amp;').replace(/&lt;/g,'&amp;lt;')
           .replace(/&gt;/g,'&amp;gt;').replace(/[ ]{2}/g, '&amp;nbsp; ')
        : v;
    }
  , br: function(v) {
      return typeof v == 'string'
        ? v.replace(/\n{2,}/g, '&lt;br/&gt;&lt;br/&gt;').replace(/\n/g, '&lt;br/&gt;')
        : v;
    }
  };

  // Updated by mindon@gmail.com Nov. 3, 2011 ( options parameter append )
  this.tmpl = function tmpl(str, data, opt){
    var _t, _f; // added by Mindon

    // Figure out if we're getting a template, or if we need to
    // load the template - and be sure to cache the result.
    var fn = !/\W/.test(str) ?
      cache[str] = cache[str] ||
        tmpl(document.getElementById(str).innerHTML, 0, opt) : // updated by Mindon

      // Appended by Mindon
      ( (_t = opt &amp;&amp; opt.html ? 1: 'tmplCall.nohtml') &amp;&amp; 
        (_f = opt &amp;&amp; opt.fields ? '(' +opt.fields +')(d)' : 1) &amp;&amp;
        ((_t===1&amp;&amp;(_t=0)) || (_f===1&amp;&amp;(_f=0))) &amp;&amp; 0
        // fields: function(){return {fieldName: handlefn(v){}}}
      ) ||

      // Generate a reusable function that will serve as a template
      // generator (and which will be cached).
      new Function("d",
        "var p=[],print=function(){p.push.apply(p,arguments);}, _f=" + _f +", _t="
          +_t +",_v=function(k,v){" 
          +'return tmplCall.br('
          +(_f?'_f[k]?_f[k](':'') +(_t?'_t(v)':'v') +(_f?'):'
          +(_t?'_t(v)':'v'):'') +")};" + // updated

        // Introduce the data as local variables using with(){}
        "p.push('" +

        // Convert the template into pure JavaScript
        str.replace(/[\r\t\n]/g, " ")
          .split("&lt;%").join("\t")
          .replace(/((^|%&gt;)[^\t]*)'/g, "$1\r")
          .replace(/\t=(.*?)%&gt;/g, "',_v('$1',d['$1']),'") // updated
          .split("\t").join("');")
          .split("%&gt;").join("p.push('")
          .split("\r").join("\\'")
      + "');return p.join('');");

    // Provide some basic currying to the user
    return data ? fn( data ) : fn;
  };
})();
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Redis: REmote DIctionary Server]]></title>
    <link href="http://mindon.github.com/blog/2012/03/17/redis-remote-dictionary-server/"/>
    <updated>2012-03-17T22:54:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/17/redis-remote-dictionary-server</id>
    <content type="html"><![CDATA[<h2>Redis tutorial</h2>

<p>These slides and notes were originally written to accompany a three hour Redis tutorial I gave at the NoSQL Europe conference on the 22nd of April 2010. <a href="http://simonwillison.net/static/2010/redis-tutorial/"><strong>Redis tutorial</strong></a></p>

<p>REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。</p>

<p><a href="http://www.petermao.com/redis/65.html">redis源代码分析</a></p>

<p><a href="http://blog.csdn.net/archimedes_zht/article/details/6909074">Redis为什么不使用Libevent或者Libev</a>
<a href="http://www.redis.io/topics/internals-eventlib">http://www.redis.io/topics/internals-eventlib</a></p>

<p><strong>Salvatore Sanfilippo：</strong>
Redis使用一个简洁的事件循环（event loop），我能够完全控制它。Libevent库自身的代码量已经是Redis目前代码量的3倍大了。</p>

<!--more-->


<p>大的库也并不总是每个方面都没有瑕疵的。例如，Libevent的稳定发布版在运行时对事件的数组做无意义的重新分配（Libevent在2.0版本里改进了这一点，但是这个版本还不是稳定的）。我修改了ae.c让它模块化，并且通过多分配一些内存为代价来避免在事件循环内部的各种类型的O(N)操作（但是这个多分配的内存对于Redis这个内存数据库来说并不是一个问题，因为可能只占总占用内存的0.001% :)）。现在添加和删除一个event是O(1)了，这对于有10K个客户端连接来说很重要。现在我们在Redis里面仅仅使用一个Timer，但是如果以后我们需要更多的，我可以修改ae.c通过使用skip list（跳跃表）来达到O(log(N))。我们现在有了2个模块：ae_select.c和ae_epoll.c，考虑到写一个新的模块的工作是如此的少，我肯定会增加ae_kevent.c。</p>

<p><strong>Sergey Shepelev：</strong>
Yeah，Libevent比较差劲，相反，libev是一个小巧、well thought、clean的库，它并没有提供任何高级的feature比如Http，但是它确实提供了非常好的底层feature。可以试一下：<a href="http://software.schmorp.de/pkg/libev.html">http://software.schmorp.de/pkg/libev.html</a></p>

<p><strong>Pedro Melo：</strong>
赞同使用Libev，使用它，你将会非常高兴满意。:)</p>

<p><strong>Salvatore Sanfilippo：</strong>
现在Redis已经支持kevents了，请看一下我在ae.c里面的新实现，它是多么简单的支持添加一个新模块，添加、删除事件都是O(1)的。底层的模块像ae_epoll.c ae_select.c ae_kevent.c仅仅导出一个最小的完美的API接口，上层则关注当前活跃的最大的FD和管理上层的状态。</p>

<p>我认为我们能够满足当前的实现而根本不用添加额外的依赖，另外这也不排除在某个时候，我们将会让我们的事件循环有一个更有意思的语义，for instance for LOCK if it will ever get implemented and for Virtual Memory (ability to "pause" events, ability to read chunks of on-disk files in background and so forth).例如：实现VM的时候，能够LOCK住事件循环，暂停事件，后台从磁盘读取文件等。我们也许要修改ae.c足够的多来让它和我们的代码一起工作而不是通过链接其他东西到Redis。当然，这有很多工作要做。</p>

<p><strong>Pedro Melo：</strong>
我的提议并不是关于添加这些模块有多简单或者复杂，我关注的是正确性。请看一下Libev的ChangLog，and seach for broken：所有这些高速的网络API都被相同OS的不同版本，或者更差的是不同的OS之间的小的不兼容困扰过。我认为Redis的主要努力不是为了创建另一个事件驱动的IO库，因此对我来说，“重用”一个已经仔细考虑过这些问题的库是更加明智的，然后把精力放在safe, working, backends上。</p>

<p><strong>Salvatore Sanfilippo：</strong>
我认为从软件工程的观点来看你是正确的，通过重用一个已经很好测试过的库，Redis的事件循环出现bug的概率会小很多。这是阻止我做正确选择的一系列things，顺便说一下，我也并不要求它们被客观接受。因此我对分歧所涉及的问题理解的很清楚：</p>

<ul>
<li><p>许多库在理论上被很好测试过了，但是如果通过一种和使用它的前N个项目不同的方式来用它，还是会发现bug的。例如，Redis唯一使用的外部代码：LZF压缩已经存在很多年了。在使用它一些天后，我发现了一个内存崩溃的bug。几乎所有人都在使用它，它也被很好测试过，但是bug仍然存在。</p></li>
<li><p>我计划以后使用很多timer。所有这些库都使用一个0(N)的定时器算法，这至少是我从源码中看到的。一个平衡树或者跳跃表可以用来提升性能。当我将需要时，我能够自己实现而不用等待外部的开发者来合并我的修改。</p></li>
<li><p>我讨厌 ./configure。事实上，在像事件循环库这种事情上，configure的魔法实际上只针对X个知名的系统。我对现在使用Redis的zero-configuration的体验非常满意。当然不使用./configure的另一种选择就是直接把代码放到Redis里面并且在发现问题时及时升级，但是我也并不想依赖于外部的源码。</p></li>
<li><p>我需要在任何地方使用 zfree/zmalloc。</p></li>
<li><p>写另一个事件循环库也是有一定价值的，如果这个库比其他的要易于阅读。例如，一些天前，我就看到某位同学在Twitter上推荐ae.c是一个关于简单事件循环很好的阅读对象，并且是能够在真实世界正确工作的。</p></li>
</ul>


<p>因此，从一个绝对的观点来看，你是正确的。但是我有一些我自己的主观原因在Redis中使用ae.c。</p>

<p><strong>Pedro Melo：</strong>
当然，不存在没有bug的库。我仅仅能够说的是libev非常的活跃，作者对在maillist上报告的bug也反应的非常快。我相信timer是O(log(N))，你可以看看文档的算法复杂度部分：http://pod.tst.eu/http://cvs.schmorp.de/libev/ev.pod#ALGORITHMIC_COMP... 。事实上，libev是将它使用的算法的复杂度文档化的少有的几个库之一。总之，我确信它将能够很好的工作。</p>

<p><strong>Salvatore Sanfilippo：</strong>
Pedro，没有任何问题，我认为你的观点是很好的，我今天读了一会儿libev代码后，也同意libev的代码很好。如果我们把这个问题当作一个纯粹的软件工程问题，换句话说，假如我们将为宇宙飞船写一个组件，毫无疑问正确的做法是使用能够工作并且被很好测试过的库。</p>

<p>但是也有其他可能的观点，并且我感觉这些观点也同等的重要（也一样不是客观的）。我认为这个讨论与编写软件最大的动机问题有很深的联系（I think this discussion has some deep link with the most important motivations for writing software.）。我认为简洁代码的价值不仅在于能够做需要做的事情，而且在于易于阅读。库是一个让伟大工作快速完成的伟大想法。Libraries are a great idea to accomplish great things in short time, but things like libev finish to  resemble every day more what they wanted to avoid, after all there was libevent already. 毕竟已经有Libevent了，它有很多bug吗？既然这样为什么不fix呢？或者开出分支出来？因为Libevent非常复杂，一团糟等等。但是最终，这些库包括libev，试图毁坏每个人最初的简单设计。需要在同一个FD上注册更多完全相同的事件？对我来说，这是一个设计错误。对通用的库来说，这是一个feature，因为有同学在使用。等等。</p>

<p>没有外部依赖也很有价值。我没有证据，但是我打赌，Redis开始吸引一些用户不仅仅是由于它作为数据库的优点，也在于它是如此易于上手。能够非常容易的理解它是怎么工作的，很容易的编译，运行甚至不需要配置。它的语义是如此的简单，以至于我知道一些同学使用不同的语言（Erlang, Java, Javascript, ... ）实现Redis的山寨版仅仅为了乐趣。</p>

<p>If you take the street of simplicity this should be adopted in everything, from the protocol to the fact there are no dependencies, and that everybody with some C skill can open ae.c and understand how an event loop works.</p>

<p>如果你认可“简洁”，也可以拓展到其他方面：从协议到没有依赖的事实，到每一个有一定C技能的同学可以打开ae.c并且理解一个事件循环是如何工作的。</p>

<p>当然我也不太确定，因为它是全新的代码。我几乎是从头编写的ae.c，但是如果有bug的话，我将能够很快的fix掉。我认为这付出的努力是值得的。顺便说下，最后一次提交之后，我已经进入了feature freeze阶段。我将利用下个月在发布rc1前的时间来从头阅读整份代码，并且做很多的测试，“简洁”在这个时候就非常有帮助了。</p>

<h2>Node.js Redis Client</h2>

<p>https://github.com/mranney/node_redis</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB: The internal file structure]]></title>
    <link href="http://mindon.github.com/blog/2012/03/17/mongodb-the-internal-file-structure/"/>
    <updated>2012-03-17T11:43:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/17/mongodb-the-internal-file-structure</id>
    <content type="html"><![CDATA[<p><a href="http://www.quora.com/Jared-Rosoff">Jared Rosoff</a></p>

<p>Each logical db has its own set of files in your dbpath. You can find them as <dbname>.<file_number>. If you're using directory-per-db option, then they may be in separate directories.</p>

<p>The dbfiles themselves are broken up into extents. Each extent is assigned to a namespace and contains data for that namespace. Each collection is its own namespace. Also each Index is its own namespace.</p>

<p>Documents in a collection are stored as a doubly linked list within extents. The document itself is formatted as BSON. There is a header that has, among other things, pointers to the next and previous document in the collection.</p>

<p>Index data is also stored in these files, but they are stored as B-Tree's rather than doubly linked lists.</p>

<p>There is also a namespace file that contains namespace (collections, indexes, freelist) meta data and how they map to their extents.</p>

<p>If you're running with journaling enabled, then there is also a set of journal files that contain a history of changes to collection data.</p>

<h2>MongoDB数据文件内部结构</h2>

<p>Origin from <a href="http://blog.nosqlfan.com/html/3515.html">http://blog.nosqlfan.com/html/3515.html</a></p>

<p>有人在Quora上提问：MongoDB数据文件内部的组织结构是什么样的。随后10gen的工程师Jared Rosoff出来做了简短的回答。</p>

<!--more-->


<p>每一个数据库都有自己独立的文件。如果你开启了directoryperdb选项，那你每个库的文件会单独放在一个文件夹里。</p>

<p>数据库文件在内部会被切分成单个的块，每个块只保存一个名字空间的数据。在MongoDB中，名字空间用于区分不同的存储类别。比如每个collection有一个独立的名字空间，每个索引也有自己的名字空间。</p>

<p>在一个块中，会保存多条记录，每条记录是BSON格式的，记录与记录之间通过双向链表进行连接。</p>

<p>索引数据也存在数据文件中，不过索引是被组织成B-Tree结构，而不是双向链表。</p>

<p>对每个数据库，有一个命名空间文件，用于保存每个名字空间对应的元数据。我们通过查询这些元数据来找到对应的名字空间的存储块位置。</p>

<p>如果你开启了jorunaling日志，那么还会有一些文件存储着你所有的操作记录。</p>

<p>下面图片摘自10gen工程师Mathias Stearn在MongoSV2011大会上的发言稿，手绘的数据文件结构。</p>

<ol>
<li><p><strong>每个数据库有相应的数据文件和命名空间文件</strong>
<img src="/images/blog/mongodb-internal/1.jpg" alt="" /></p></li>
<li><p><strong>数据文件从16MB开始，新的数据文件比上一个文件大一倍，最大为2GB</strong>
<img src="/images/blog/mongodb-internal/2.jpg" alt="" /></p></li>
<li><p><strong>文件使用MMAP进行内存映射，会将所有数据文件映射到内存中，但是只是虚拟内存，只有访问到这块数据时才会交换到物理内存。</strong>
<img src="/images/blog/mongodb-internal/3.jpg" alt="" />
<img src="/images/blog/mongodb-internal/3-0.jpg" alt="" /></p></li>
<li><p><strong>MongoDB的数据文件映射到内存表中的位置</strong>
<img src="/images/blog/mongodb-internal/4.jpg" alt="" />
<img src="/images/blog/mongodb-internal/4-0.jpg" alt="" /></p></li>
<li><p><strong>使用32位机器的话，内存地址最大可以标识4GB内存</strong>
<img src="/images/blog/mongodb-internal/5.jpg" alt="" />
<img src="/images/blog/mongodb-internal/5-0.jpg" alt="" /></p></li>
<li><p><strong>但是在32位机器上，4GB内存会有1GB被内核战用，大约0.5GB会用于mongod进程的stack空间，只剩下大约2.5GB可用于映射数据文件。</strong>
<img src="/images/blog/mongodb-internal/6.jpg" alt="" />
<img src="/images/blog/mongodb-internal/6-0.jpg" alt="" /></p></li>
<li><p><strong>在64位机器上则最多可以表示128TB的空间</strong>
<img src="/images/blog/mongodb-internal/7.jpg" alt="" />
<img src="/images/blog/mongodb-internal/7-0.jpg" alt="" />
<img src="/images/blog/mongodb-internal/7-1.jpg" alt="" /></p></li>
<li><p><strong>每个数据文件会被分成一个一个的数据块，块与块之间用双向链表连接</strong>
<img src="/images/blog/mongodb-internal/8.jpg" alt="" />
<img src="/images/blog/mongodb-internal/8.jpg" alt="" /></p></li>
<li><p><strong>在名字空间文件中，保存的是一个hash table，保存了每个名字空间的存储信息元数据，包括其大小，块数，第一块位置，最后一块位置，被删除的块的链表以及索引信息</strong>
<img src="/images/blog/mongodb-internal/9.jpg" alt="" />
<img src="/images/blog/mongodb-internal/9-0.jpg" alt="" /></p></li>
<li><p><strong>这些位置通过DiskLoc数据结构进行存储，存储了数据文件编号和块在文件中的位置</strong>
<img src="/images/blog/mongodb-internal/a.jpg" alt="" />
<img src="/images/blog/mongodb-internal/a-0.jpg" alt="" />
<img src="/images/blog/mongodb-internal/a-1.jpg" alt="" />
<img src="/images/blog/mongodb-internal/a-2.jpg" alt="" /></p></li>
<li><p><strong>对每一个块来说，其头部包含了一些块的元数据，比如自己的位置，上一个和下一个块的位置以及块中第一条和最后一条记录的位置指针。剩下的部分用于存储具体的数据，具体数据之间也是通过双向链接来进行连接。</strong>
<img src="/images/blog/mongodb-internal/b.jpg" alt="" />
<img src="/images/blog/mongodb-internal/b-0.jpg" alt="" />
<img src="/images/blog/mongodb-internal/b-1.jpg" alt="" /></p></li>
<li><p><strong>下面是B-Tree的存储结构和工作原理</strong>
<img src="/images/blog/mongodb-internal/c.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-0.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-1.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-2.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-3.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-4.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-5.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-6.jpg" alt="" />
<img src="/images/blog/mongodb-internal/c-7.jpg" alt="" /></p></li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Notes on MongoDB]]></title>
    <link href="http://mindon.github.com/blog/2012/03/17/notes-on-mongodb/"/>
    <updated>2012-03-17T11:12:00+08:00</updated>
    <id>http://mindon.github.com/blog/2012/03/17/notes-on-mongodb</id>
    <content type="html"><![CDATA[<p><strong>MongoDB资料汇总专题</strong>
<a href="http://blog.nosqlfan.com/html/3548.html">http://blog.nosqlfan.com/html/3548.html</a></p>

<h2>MongoDB 最佳实践</h2>

<p>Original from <a href="http://www.oschina.net/question/12_38878">http://www.oschina.net/question/12_38878</a></p>

<p><strong>1. 始终启用备份</strong></p>

<p>备份能保证你应用的高可用性。假如你的一个节点down了，第
二节点可以迅速启用，你的应用不会中断。</p>

<p><strong>2. 使用最新版本</strong></p>

<p>10gen在不断的发布更新，特别是2.0.x包含了很高的性能提升
和并行改进，索引改进和bug修复。如果你还在使用 1.6.3的话
，你应该尽快升级。</p>

<!--more-->


<p><strong>3. 不要在32位的系统上跑MongoDB</strong></p>

<p>MongoDB在32位系统上有“2.5GB数据限制”。它的存储引擎使用
内存映射来读取文件以获得更好的性能。这个功能依赖于内存
寻址，而32位系统的内存不能超过4GB。</p>

<p><strong>4. 默认开启日志</strong></p>

<p>MongoDB支持数据库操作的提前日志（write-ahead journaling
）。这个功能有助于灾难恢复。</p>

<p><strong>5. 注意你数据文件的位置</strong></p>

<p>你应该保证你的MongoDB的数据文件是存储在物理驱动器上，例
如 /data/mongodb。当然你也可以使用虚拟的驱动器，但是必
须非常小心。因为它有可能会影响到你的集群架构。我们建议
你使用 Amazon EBS 来存放你的数据库文件。</p>

<p><strong>6. 保证足够大的内存</strong></p>

<p>为了保证整个集群的性能，你要确保整个所有MongoDB的工作实
例（working set）包括索引可以完全装入内存。如果你发现
“page faults”的概率在增加，很有可能mongoDB的数据量超出
了你的内存。在这种情况下你有两种选择：加内存，或者创建
分片集群（Sharding）。我们建议你先考虑加内存。</p>

<p><strong>7. 保持 65% 以内的压力</strong></p>

<p>如果你发现你的集群压力达到了65%，那么你应该考虑扩大你的
集群了。通常，你应该保证数据库压力低于65%。</p>

<p><strong>8. 特别小心分片集群</strong></p>

<p>分片集群需要你充分理解你应用的数据访问方式。你应该充分
了解MongoDB的分片工作方式，并且确认你确实需要这个功能。
还有，选择一个分片钥匙（sharding key）是对于性能也是很
重要的。</p>

<p>配置服务器对于一个集群的健康也是很重要的。在分片集群的
环境中，你必须有三台配置服务器。永远不要删除配置服务器
的数据，时常备份这些数据。这些配置服务器也需要64位的环
境。还有，不要把三台配置服务器放在同一台机器上！</p>

<p><strong>9. 使用 Mongo MMS 来图形化的监控你的数据库</strong></p>

<p>如果你还没有使用 Mongo MMS的话，我强烈推荐这个工具。
10gen 正在大力开发这个产品。它提供了一个非常友好的可视
化的界面来监控你的MongoDB集群。</p>

<p><strong>10. MongoDB 资源</strong></p>

<p>技术总是在不断进步，你需要市场关注这些信息：</p>

<ul>
<li>Documentation: <a href="http://www.mongodb.org/display/DOCS/Home">http://www.mongodb.org/display/DOCS/Home</a></li>
<li>Google Group: <a href="http://groups.google.com/group/mongodb-user">http://groups.google.com/group/mongodb-user</a></li>
<li>Bugs: <a href="https://jira.mongodb.org">https://jira.mongodb.org</a></li>
<li>Blog: <a href="http://blog.mongodb.org/">http://blog.mongodb.org/</a></li>
</ul>


<p><a href="http://www.engineyard.com/blog/2011/mongodb-best-practices/"><strong>MongoDB Best Practices</strong></a> <a href="http://www.programmer.com.cn/9999/">中文</a></p>

<p><strong>MongoDB运行状态、性能监控，分析</strong>:
<a href="http://blog.nosqlfan.com/html/3346.html">http://blog.nosqlfan.com/html/3346.html</a></p>

<p><strong>MongoDB容量规划</strong>:
<a href="http://blog.nosqlfan.com/html/3322.html">http://blog.nosqlfan.com/html/3322.html</a></p>

<p><strong>MongoQ</strong>:
<a href="https://github.com/zzdhidden/mongoq">https://github.com/zzdhidden/mongoq</a></p>

<p><strong>MongoSpy, MongoWatch及MongoDB数据压缩</strong></p>

<p><a href="http://blog.nosqlfan.com/html/3205.html">http://blog.nosqlfan.com/html/3205.html</a></p>

<h2>五步优化你的MongoDB</h2>

<ol>
<li><p><strong>查询优化</strong>
确认你的查询是否充分利用到了索引，用explain命令查看一下查询执行的情况，添加必要的索引，避免扫表操作。</p></li>
<li><p><strong>搞清你的热数据大小</strong>
可能你的数据集非常大，但是这并不那么重要，重要的是你的热数据集有多大，你经常访问的数据有多大（包括经常访问的数据和所有索引数据）。使用MongoDB，你最好保证你的热数据在你机器的内存大小之下，保证内存能容纳所有热数据。</p></li>
<li><p><strong>选择正确的文件系统</strong>
MongoDB的数据文件是采用的预分配模式，并且在Replication里面，Master和Replica Sets的非Arbiter节点都是会预先创建足够的空文件用以存储操作日志。这些文件分配操作在一些文件系统上可能会非常慢，导致进程被Block。所以我们应该选择那些空间分配快速的文件系统。这里的结论是尽量不要用ext3，用ext4或者xfs。</p></li>
<li><p><strong>选择合适的硬盘</strong>
这里的选择包括了对磁盘RAID的选择，也包括了磁盘与SSD的对比选择。</p></li>
<li><p><strong>Shard分片</strong>
在单个节点压力太大时，我们可以考虑使用MongoDB的auto-sharding机制来将数据分片到多个节点以缓解压力。</p></li>
</ol>


<p>火丁筆記: <a href="http://huoding.com/2011/08/09/104">记一次MongoDB性能问题</a></p>

<p><strong>NUMA Problem（Warn)</strong>
<a href="http://www.mongodb.org/display/DOCS/NUMA">http://www.mongodb.org/display/DOCS/NUMA</a></p>

<p>shell> numactl --interleave=all /path/to/mongod</p>

<p>NUMA下，内存是按照物理CPU来划分的，不是按逻辑CPU/核划分的</p>

<p>每个核访问分配给自己的内存会比访问分配给其它核的内存要快，有下面几种访问控制策略：</p>

<ol>
<li><p>缺省(default)：总是在本地节点分配（分配在当前进程运行的节点上）；</p></li>
<li><p>绑定(bind)：强制分配到指定节点上；3.交叉(interleave)：在所有节点或者指定的节点上交织分配；</p></li>
<li><p>优先(preferred)：在指定节点上分配，失败则在其他节点上分配。</p></li>
</ol>

]]></content>
  </entry>
  
</feed>
